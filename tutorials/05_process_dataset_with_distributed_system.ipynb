{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10149032-ef13-4065-862a-fc25820f300a",
   "metadata": {},
   "source": [
    "# Process data with distributed system\n",
    "\n",
    "This tutorial demonstrates how to use given data_recipes to process data using Data-Juicer in distributed system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc8518",
   "metadata": {},
   "source": [
    "First of all, `cd` into the Data-Juicer directory to use it as the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a185dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to your data-juicer directory.\n",
    "%cd ~/data-juicer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95210f",
   "metadata": {},
   "source": [
    "### Process data using data-jucier with distributed system with Ray\n",
    "\n",
    "First we show how to process data using data-jucier with [ray](https://docs.ray.io/en/latest/).\n",
    "Ray provides a set of powerful abstractions that enable developers to efficiently execute parallel tasks with minimal effort. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781109b2",
   "metadata": {},
   "source": [
    "To process data using data-jucier with ray, first install all the dependencies for data-jucier distributed system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4849080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the dependencies\n",
    "# !pip install -e .\\[dist\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdee664",
   "metadata": {},
   "source": [
    "Then you need to start your ray server.\n",
    "\n",
    "``` sh\n",
    "# in ray server node\n",
    "ray start --head\n",
    "```\n",
    "\n",
    "If you are using multiple nodes, you need to start ray accross all nodes.\n",
    "\n",
    "``` sh\n",
    "# in other nodes\n",
    "ray start --address=\"xxx.xxx.xxx.xxx:6379\" # change address to server ip\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4205f8c",
   "metadata": {},
   "source": [
    "In the config file(e.g. [./demos/process_on_ray/configs/demo.yaml](https://github.com/modelscope/data-juicer/blob/main/demos/process_on_ray/configs/demo.yaml)), set the executor_type to 'ray' accordingly.\n",
    "``` yaml\n",
    "    ...\n",
    "    executor_type: 'ray'\n",
    "    ray_address: 'auto'   \n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f4be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then you can run the ray demo on data-juicer\n",
    "!python tools/process_data.py --config ./demos/process_on_ray/configs/demo.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee0aa1e",
   "metadata": {},
   "source": [
    "Ray can seamlessly scale from a single machine to a large cluster without major modifications to the code. \n",
    "Readers can refer to the source code of the corresponding Ray executor file [ray_executor.py](https://github.com/modelscope/data-juicer/blob/main/data_juicer/core/ray_executor.py) and compare it to [executor.py](https://github.com/modelscope/data-juicer/blob/main/data_juicer/core/executor.py) to understand the relevant processing methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5b8373",
   "metadata": {},
   "source": [
    "> NOTE: If you are processing multimodal data such as images/videos, please ensure that the corresponding data has been stored in the appropriate file sharing system (e.g., NAS), and that all nodes in the cluster have access to the paths within the file sharing system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7682292d",
   "metadata": {},
   "source": [
    "### Process data using data-jucier with distributed system with Slurm/DLC\n",
    "\n",
    "At the same time, data can be processed using distributed systems such as a Slurm cluster. Here is an example of processing video data in [run_slurm.sh](https://github.com/modelscope/data-juicer/blob/main/scripts/run_slurm.sh).\n",
    "\n",
    "In order to run on clusters such as Slurm, a data partitioning script, such as [partition_data_dlc.py](https://github.com/modelscope/data-juicer/blob/main/scripts/dlc/partition_data_dlc.py), is first used to distribute the data across different nodes. Subsequently, the srun command is utilized to launch individual instances of data-juicer on each machine.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
